---
phase: 12-core-integration-layer
plan: 03
type: execute
domain: mcp-server
---

<objective>
Implement Tier 3 performance and comparison MCP tools for chart data, period returns, and backtest vs actual comparison.

Purpose: Complete the MCP tool suite with performance visualization data and trading calendar comparison.
Output: 3 performance tools (get_performance_charts, get_period_returns, compare_backtest_to_actual) completing the Phase 12 tool set.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary-frontmatter.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-core-integration-layer/12-RESEARCH.md
@.planning/phases/12-core-integration-layer/12-01-SUMMARY.md
@.planning/phases/12-core-integration-layer/12-02-SUMMARY.md

# Key source files
@lib/services/performance-snapshot.ts
@lib/services/calendar-data.ts
@lib/calculations/performance.ts
@lib/processing/reporting-log-processor.ts

# MCP server from Plans 01-02
@packages/mcp-server/src/index.ts
@packages/mcp-server/src/utils/block-loader.ts
@packages/mcp-server/src/utils/output-formatter.ts

**Depends on:** Plans 12-01 and 12-02 (block loading, formatters, analysis tools)

**Key services:**
- buildPerformanceSnapshot - Equity curve, drawdown, returns data
- scaleStrategyComparison - Backtest vs actual with scaling modes
- calculatePeriodReturns - Monthly/weekly/daily P&L breakdown
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement performance data tools</name>
  <files>packages/mcp-server/src/tools/performance.ts</files>
  <action>
Create performance.ts with tool registration functions:

**get_performance_charts** - Get data for performance visualizations
Schema:
```typescript
{
  blockId: z.string(),
  strategy: z.string().optional(),
  charts: z.array(z.enum([
    'equity_curve',
    'drawdown',
    'monthly_returns',
    'return_distribution',
    'day_of_week'
  ])).default(['equity_curve', 'drawdown', 'monthly_returns'])
}
```
- Build equity curve from trades (cumulative P/L over time)
- Calculate drawdown series (peak-to-trough)
- Generate monthly returns matrix (year x month)
- Return distribution histogram (P/L buckets)
- Day of week average P/L
- Return: Selected chart data as structured markdown tables

**get_period_returns** - Monthly/weekly P&L breakdown
Schema:
```typescript
{
  blockId: z.string(),
  strategy: z.string().optional(),
  period: z.enum(['monthly', 'weekly', 'daily']).default('monthly'),
  year: z.number().optional().describe("Filter to specific year")
}
```
- Group trades by period using dateOpened
- Calculate gross P/L, commissions, net P/L per period
- Handle timezone correctly (Eastern time)
- Return: Period breakdown table with totals

Note: For equity curve and drawdown, compute from trade sequence if no daily logs, or use daily logs for more accurate curve when available.
  </action>
  <verify>pnpm --filter tradeblocks-mcp build succeeds; tools appear in server tool list</verify>
  <done>get_performance_charts and get_period_returns tools registered with proper chart data output</done>
</task>

<task type="auto">
  <name>Task 2: Implement backtest vs actual comparison tool</name>
  <files>packages/mcp-server/src/tools/performance.ts, packages/mcp-server/src/utils/block-loader.ts, packages/mcp-server/src/index.ts</files>
  <action>
Add the final Tier 3 tool and complete server integration:

**Update block-loader.ts:**
- Add `loadReportingLog(blockPath)` function for reportinglog.csv
- Use ReportingLogProcessor from @lib/processing if available, or simple CSV parse
- Return ReportingTrade[] array

**compare_backtest_to_actual** - Trading calendar comparison
Schema:
```typescript
{
  blockId: z.string(),
  scaling: z.enum(['raw', 'perContract', 'toReported']).default('raw').describe(
    "raw: no scaling, perContract: divide by contracts, toReported: scale backtest to match actual size"
  )
}
```
- Load tradelog.csv as backtest trades
- Load reportinglog.csv as actual trades (error if not present)
- Match trades by date and compute differences
- Apply scaling mode (see CLAUDE.md for scaling logic)
- Return: Daily comparison table, total variance, correlation

**Update index.ts:**
- Import registerPerformanceTools from tools/performance.ts
- Call registerPerformanceTools(server, resolvedDir) after analysis tools
- Total tools: 14 (6 core + 5 analysis + 3 performance)
  </action>
  <verify>pnpm --filter tradeblocks-mcp build succeeds; all 14 tools listed; compare_backtest_to_actual returns error for blocks without reportinglog.csv</verify>
  <done>All 14 MCP tools implemented; compare_backtest_to_actual handles scaling modes; server fully functional</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete MCP server with 14 tools covering all TradeBlocks features</what-built>
  <how-to-verify>
    1. Build MCP server: `pnpm --filter tradeblocks-mcp build`
    2. Create test folder with sample tradelog.csv: `mkdir -p ~/test-backtests/my-strategy && cp tests/data/sample-trades.csv ~/test-backtests/my-strategy/tradelog.csv` (or create simple test CSV)
    3. Run server: `node packages/mcp-server/dist/index.js ~/test-backtests`
    4. Server should print "TradeBlocks MCP ready. Watching: /Users/.../test-backtests"
    5. (Optional) Test with Claude Desktop by adding to claude_desktop_config.json
  </how-to-verify>
  <resume-signal>Type "approved" to continue, or describe issues to fix</resume-signal>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `pnpm --filter tradeblocks-mcp build` succeeds
- [ ] `pnpm run lint` passes
- [ ] All 14 tools registered (6 core + 5 analysis + 3 performance)
- [ ] compare_backtest_to_actual properly handles missing reportinglog.csv
- [ ] Performance chart data correctly formatted
- [ ] Human verification checkpoint passed
</verification>

<success_criteria>

- 3 Tier 3 performance tools registered and callable
- All 14 Phase 12 tools complete and working
- compare_backtest_to_actual implements all three scaling modes
- Server verified working with test data
- Phase 12: Core Integration Layer complete
</success_criteria>

<output>
After completion, create `.planning/phases/12-core-integration-layer/12-03-SUMMARY.md` using the summary template.

Include in summary:
- Total tools implemented: 14
- Tool tiers breakdown
- Any deviations from research tool design
- Ready for Phase 13: Analysis Capabilities
</output>
