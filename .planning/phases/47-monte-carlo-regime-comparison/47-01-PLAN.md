---
phase: 47-monte-carlo-regime-comparison
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - packages/lib/calculations/mc-regime-comparison.ts
  - packages/lib/calculations/rolling-metrics.ts
  - packages/lib/calculations/index.ts
  - tests/unit/mc-regime-comparison.test.ts
autonomous: true

must_haves:
  truths:
    - "Monte Carlo simulation runs on full trade history using percentage-based resampling and returns SimulationStatistics"
    - "Monte Carlo simulation runs on only the recent window trades (configurable, default from calculateDefaultRecentWindow) and returns SimulationStatistics"
    - "P(Profit), expected return (meanTotalReturn), Sharpe (meanSharpeRatio), and median max drawdown are compared between full-history and recent-window simulations with delta and percent change"
    - "Regime divergence is classified into exactly one of: aligned, mild_divergence, significant_divergence, regime_break based on composite divergence score"
  artifacts:
    - path: "packages/lib/calculations/mc-regime-comparison.ts"
      provides: "MC regime comparison engine with dual simulation, metric comparison, and divergence classification"
      exports: ["runRegimeComparison", "classifyDivergence", "MCRegimeComparisonOptions", "MCRegimeComparisonResult", "MetricComparison", "DivergenceSeverity"]
    - path: "tests/unit/mc-regime-comparison.test.ts"
      provides: "Test coverage for regime comparison engine"
  key_links:
    - from: "packages/lib/calculations/mc-regime-comparison.ts"
      to: "packages/lib/calculations/monte-carlo.ts"
      via: "runMonteCarloSimulation for both full and recent window simulations"
      pattern: "runMonteCarloSimulation"
    - from: "packages/lib/calculations/mc-regime-comparison.ts"
      to: "packages/lib/calculations/rolling-metrics.ts"
      via: "calculateDefaultRecentWindow for default recent window sizing"
      pattern: "calculateDefaultRecentWindow"
    - from: "packages/lib/calculations/index.ts"
      to: "packages/lib/calculations/mc-regime-comparison.ts"
      via: "barrel export"
      pattern: "export \\* from './mc-regime-comparison'"
---

<objective>
Build the Monte Carlo regime comparison calculation engine that runs dual simulations (full history vs recent window), compares four key metrics, and classifies divergence severity.

Purpose: This is the core calculation for Phase 47 -- it calls `runMonteCarloSimulation` twice with different trade pools, computes metric deltas, and classifies the divergence into severity levels. Consumed by the MCP tool in Plan 02 and by the verdict synthesis in Phase 50.

Output: New calculation file (`mc-regime-comparison.ts`), exported `calculateDefaultRecentWindow` from rolling-metrics.ts, barrel exports updated, and comprehensive TDD tests.
</objective>

<execution_context>
@/Users/davidromeo/.claude/get-shit-done/workflows/execute-plan.md
@/Users/davidromeo/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/47-monte-carlo-regime-comparison/47-RESEARCH.md
@packages/lib/calculations/monte-carlo.ts
@packages/lib/calculations/rolling-metrics.ts
@packages/lib/calculations/index.ts
@packages/lib/models/trade.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Export calculateDefaultRecentWindow and create MC regime comparison engine</name>
  <files>
    packages/lib/calculations/rolling-metrics.ts
    packages/lib/calculations/mc-regime-comparison.ts
    packages/lib/calculations/index.ts
  </files>
  <action>
**1. Export `calculateDefaultRecentWindow` from `rolling-metrics.ts`**

Change the function declaration from `function calculateDefaultRecentWindow` to `export function calculateDefaultRecentWindow` (line 132). No other changes to this file.

**2. Create `packages/lib/calculations/mc-regime-comparison.ts`**

This is a thin wrapper over the existing Monte Carlo engine. Import from sibling modules:

```typescript
import { Trade } from '../models/trade'
import { runMonteCarloSimulation, getTradeResamplePool, calculatePercentageReturns } from './monte-carlo'
import type { MonteCarloParams, SimulationStatistics } from './monte-carlo'
import { calculateDefaultRecentWindow } from './rolling-metrics'
```

**Types:**

```typescript
export type DivergenceSeverity = 'aligned' | 'mild_divergence' | 'significant_divergence' | 'regime_break'

export interface MetricComparison {
  metric: string
  fullHistoryValue: number
  recentWindowValue: number
  delta: number
  percentChange: number | null  // null if fullHistory is 0
  /** Per-metric normalized divergence score (0 = identical, higher = more divergent) */
  divergenceScore: number
}

export interface MCRegimeComparisonOptions {
  /** Number of recent trades to use for recent window simulation. Default: auto-calculated via calculateDefaultRecentWindow. */
  recentWindowSize?: number
  /** Number of simulations per MC run. Default: 1000. */
  numSimulations?: number
  /** Number of trades to project forward in each simulation. Default: recentWindowSize. */
  simulationLength?: number
  /** Starting capital for simulations. Default: inferred from first trade's fundsAtClose. */
  initialCapital?: number
  /** Random seed for reproducibility. Default: 42. */
  randomSeed?: number
  /** Expected trades per year. Default: auto-calculated from full history date range. */
  tradesPerYear?: number
  /** Filter to specific strategy (case-insensitive). */
  strategy?: string
}

export interface MCRegimeComparisonResult {
  fullHistory: {
    statistics: SimulationStatistics
    tradeCount: number
    dateRange: { start: string; end: string }
  }
  recentWindow: {
    statistics: SimulationStatistics
    tradeCount: number
    dateRange: { start: string; end: string }
  }
  comparison: MetricComparison[]
  divergence: {
    severity: DivergenceSeverity
    compositeScore: number
    /** Brief factual description of the composite score */
    scoreDescription: string
  }
  parameters: {
    recentWindowSize: number
    numSimulations: number
    simulationLength: number
    initialCapital: number
    tradesPerYear: number
    randomSeed: number
  }
}
```

**Main function: `runRegimeComparison(trades: Trade[], options?: MCRegimeComparisonOptions): MCRegimeComparisonResult`**

Implementation:

1. **Filter by strategy** (if provided): `trades.filter(t => t.strategy.toLowerCase() === strategy.toLowerCase())`.

2. **Sort trades** chronologically by dateOpened.

3. **Validate**: If filtered trades < 30, throw Error "Insufficient trades for regime comparison. Found N, need at least 30."

4. **Resolve defaults**:
   - `recentWindowSize`: `options?.recentWindowSize ?? calculateDefaultRecentWindow(trades.length)`. Clamp: if recentWindowSize >= trades.length, set to `Math.floor(trades.length * 0.5)` (need SOME historical trades).
   - `numSimulations`: `options?.numSimulations ?? 1000`
   - `simulationLength`: `options?.simulationLength ?? recentWindowSize`
   - `randomSeed`: `options?.randomSeed ?? 42`
   - `tradesPerYear`: `options?.tradesPerYear ?? calculateTradesPerYear(sortedTrades)` (helper function below)
   - `initialCapital`: `options?.initialCapital ?? inferInitialCapital(sortedTrades)` (helper: first trade's fundsAtClose - pl, minimum 1)

5. **Build trade pools**:
   - Full pool: all sorted trades
   - Recent pool: `sortedTrades.slice(-recentWindowSize)`

6. **Run MC on full history**:
   ```typescript
   const fullParams: MonteCarloParams = {
     numSimulations,
     simulationLength,
     resampleMethod: 'percentage',
     initialCapital,
     tradesPerYear,
     randomSeed,
     worstCaseEnabled: false,
   }
   const fullResult = runMonteCarloSimulation(fullPool, fullParams)
   ```

7. **Run MC on recent window**:
   ```typescript
   const recentParams: MonteCarloParams = {
     ...fullParams,
     randomSeed: randomSeed + 10000,  // Different seed to avoid correlation
   }
   const recentResult = runMonteCarloSimulation(recentPool, recentParams)
   ```

8. **Compare four metrics** (MCRG-03):
   - `probabilityOfProfit`: fullResult.statistics.probabilityOfProfit vs recentResult
   - `expectedReturn` (meanTotalReturn): fullResult.statistics.meanTotalReturn vs recentResult
   - `sharpeRatio` (meanSharpeRatio): fullResult.statistics.meanSharpeRatio vs recentResult
   - `medianMaxDrawdown`: fullResult.statistics.medianMaxDrawdown vs recentResult

   For each metric, compute:
   - `delta = recentValue - fullHistoryValue`
   - `percentChange = fullHistoryValue !== 0 ? (delta / Math.abs(fullHistoryValue)) * 100 : null`
   - `divergenceScore` = normalized per-metric divergence (see classification section below)

9. **Classify divergence** (MCRG-04):

   Export a pure function `classifyDivergence(comparisons: MetricComparison[]): { severity: DivergenceSeverity; compositeScore: number; scoreDescription: string }`.

   Per-metric divergence scores (normalize to comparable scales):
   - `probabilityOfProfit`: `|delta| / 0.10` (10pp difference = score of 1.0)
   - `expectedReturn`: `|delta| / max(0.01, |fullValue|)` (100% relative change = 1.0). Cap at 5.0 to avoid outlier domination.
   - `sharpeRatio`: `|delta| / max(0.5, |fullValue|)` (halving Sharpe = 1.0). Cap at 5.0.
   - `medianMaxDrawdown`: `|delta| / max(0.01, fullValue)` (100% relative change = 1.0). Cap at 5.0.

   Composite score = mean of the four per-metric divergence scores.

   Classification thresholds:
   - `compositeScore < 0.30` -> `aligned`
   - `compositeScore < 0.60` -> `mild_divergence`
   - `compositeScore < 1.00` -> `significant_divergence`
   - `compositeScore >= 1.00` -> `regime_break`

   `scoreDescription`: a factual string like "Composite divergence score 0.45 (mean of 4 metric divergences)" -- NO interpretive labels beyond the severity enum itself.

10. **Build result**: Include date ranges from first/last trade in each pool (format as YYYY-MM-DD using local time). Include resolved parameters.

**Helper functions (private, not exported):**

- `calculateTradesPerYear(sortedTrades: Trade[]): number` -- calculates from date range: `trades.length / (dateRangeInDays / 365.25)`. Minimum 1.
- `inferInitialCapital(sortedTrades: Trade[]): number` -- `Math.max(1, sortedTrades[0].fundsAtClose - sortedTrades[0].pl)`.
- `formatLocalDate(date: Date): string` -- same pattern as rolling-metrics.ts: `${y}-${mm}-${dd}` using getFullYear/getMonth/getDate.

**3. Update `packages/lib/calculations/index.ts`**

Add one new export line after the existing `export * from './rolling-metrics'` line:
```typescript
export * from './mc-regime-comparison'
```

**IMPORTANT constraints:**
- Use `resampleMethod: 'percentage'` for both simulations (per MCRG-01).
- Do NOT return full simulation paths (equityCurve arrays) -- only return SimulationStatistics.
- Default `worstCaseEnabled: false` -- worst-case injection is NOT part of regime comparison.
- Use deterministic `randomSeed` (default 42) for reproducibility.
- Different seeds for full vs recent to avoid correlated randomness.
  </action>
  <verify>
Run `npm run build --workspace=packages/lib` to confirm no TypeScript errors.
  </verify>
  <done>
- `rolling-metrics.ts` exports `calculateDefaultRecentWindow`
- `mc-regime-comparison.ts` exports `runRegimeComparison`, `classifyDivergence`, and all type interfaces
- `index.ts` barrel-exports the new module
- No TypeScript errors
  </done>
</task>

<task type="auto">
  <name>Task 2: TDD tests for MC regime comparison engine</name>
  <files>
    tests/unit/mc-regime-comparison.test.ts
  </files>
  <action>
Create comprehensive tests for the MC regime comparison engine. Use existing test patterns (import from `@tradeblocks/lib`, Jest).

Create a helper `makeTrade(overrides: Partial<Trade>): Trade` that fills in sensible defaults. Create a `generateTradeSet(count: number, options?: { winRate?: number, avgPl?: number, startDate?: Date, strategy?: string }): Trade[]` helper that generates realistic trade arrays with controllable win rates.

**Test cases for `runRegimeComparison`:**

1. **Insufficient trades**: < 30 trades throws Error with descriptive message.
2. **Basic execution with 50 trades**: runs without error, returns all expected fields (fullHistory, recentWindow, comparison, divergence, parameters).
3. **Default recentWindowSize**: verify it uses `calculateDefaultRecentWindow` formula -- for 500 trades, recent window should be max(20% * 500, 200) = 200.
4. **Custom recentWindowSize**: pass `recentWindowSize: 30`, verify recent pool has 30 trades.
5. **Strategy filter**: create trades with mixed strategies, filter to one. Verify only that strategy's trades are used.
6. **Both simulations use percentage resampleMethod**: inspect returned parameters.
7. **Date ranges correct**: verify fullHistory dateRange spans all trades, recentWindow dateRange spans only recent N.
8. **Comparison has exactly 4 metrics**: probabilityOfProfit, expectedReturn, sharpeRatio, medianMaxDrawdown.
9. **RecentWindowSize clamping**: if recentWindowSize >= trade count, it gets clamped to 50% of trade count.

**Test cases for `classifyDivergence`:**

10. **Aligned**: all metric divergence scores near 0 -> severity = 'aligned', compositeScore < 0.30.
11. **Mild divergence**: moderate divergences -> severity = 'mild_divergence', compositeScore between 0.30 and 0.60.
12. **Significant divergence**: large divergences -> severity = 'significant_divergence', compositeScore between 0.60 and 1.00.
13. **Regime break**: extreme divergences -> severity = 'regime_break', compositeScore >= 1.00.
14. **Score description is factual**: verify scoreDescription contains the composite score value and no interpretive labels beyond the severity enum.

**Test cases for edge cases:**

15. **Deterministic with same seed**: running twice with same seed produces identical results.
16. **All winning trades**: P(Profit) should be high for both pools, divergence should be low.
17. **Recent window much worse**: create trades where first 400 are profitable, last 100 have 30% win rate. Verify divergence severity is at least 'mild_divergence'.

Use `numSimulations: 100` in tests (not 1000) for speed. Use `randomSeed: 42` for determinism.

Run tests with: `npm test -- tests/unit/mc-regime-comparison.test.ts`

Target: All tests pass. At least 15 test cases.
  </action>
  <verify>
`npm test -- tests/unit/mc-regime-comparison.test.ts` passes with all tests green.
  </verify>
  <done>
- At least 15 test cases pass covering runRegimeComparison, classifyDivergence, and edge cases
- Determinism verified with fixed random seed
- Classification thresholds verified with controlled inputs
- Strategy filtering verified
  </done>
</task>

</tasks>

<verification>
1. `npm run build --workspace=packages/lib` succeeds with no errors
2. `npm test -- tests/unit/mc-regime-comparison.test.ts` -- all tests pass
3. `npm test` -- full test suite still passes (no regressions)
4. No interpretive labels in calculation code (grep for "improving", "deteriorating", "healthy", "unhealthy" in new files -- should return nothing)
</verification>

<success_criteria>
- MC regime comparison engine calls runMonteCarloSimulation twice (full pool, recent pool) with percentage-based resampling
- Four metrics compared: P(Profit), expected return, Sharpe, median max drawdown
- Divergence classified into aligned / mild_divergence / significant_divergence / regime_break via composite score
- calculateDefaultRecentWindow exported from rolling-metrics.ts for reuse
- All tests pass with deterministic seeds
</success_criteria>

<output>
After completion, create `.planning/phases/47-monte-carlo-regime-comparison/47-01-SUMMARY.md`
</output>
